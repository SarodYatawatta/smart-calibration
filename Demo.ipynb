{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Calibration -- Demo\n",
    "\n",
    "## Introduction\n",
    "Image classification using a deep neural network. Example CIFAR10 images (32x32 pixels, 10 classes: plane, car, bird ..).\n",
    "<img src=\"./tmp/cifar10.png\" alt=\"Alexnet untrained\" width=\"400\"/>\n",
    "\n",
    "Deep NN are trained to perform classification using training data and tested using test data.\n",
    "<img src=\"./tmp/losses.png\" alt=\"Alexnet untrained\" width=\"500\"/>\n",
    "Almost always, test accuracy is lower than train accuracy. Why?\n",
    "\n",
    "Influence function [Cook and Weisberg, 1982](https://books.google.nl/books?id=MVSqAAAAIAAJ&hl=nl) can be used to study this. Recent re-discovery in machine learning [Koh and Liang, 2017](http://proceedings.mlr.press/v70/koh17a.html) and in radio astronomy [Yatawatta, 2018](https://ieeexplore.ieee.org/abstract/document/8448481) [Yatawatta, 2019](https://academic.oup.com/mnras/article/486/4/5646/5484901).\n",
    "What is it? *small changes* in input leads to *small changes* in output, we find this for the trained model.\n",
    "\n",
    "Example: Untrained model, AlexNet. Noise like influence function. Accuracy 10%.\n",
    "<img src=\"./figures/alexnet_untrained.png\" alt=\"Alexnet untrained\" width=\"400\"/>\n",
    "\n",
    "Trained model, AlexNet, 2.4 million parameters, test accuracy 65%. See the patterns, which indicate *bias*.\n",
    "<img src=\"./figures/alexnet_trained.png\" alt=\"Alexnet trained\" width=\"400\"/>\n",
    "\n",
    "Trained model, ResNet18, 11 million parameters, test accuracy 85%. Almost noise like influence function.\n",
    "<img src=\"./figures/resnet18_trained.png\" alt=\"ResNet18 trained\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "In CIFAR10 deep neural network training: we have *ground truth*  information, in radio astronomy we do not have this. Influence function *does not need* the ground truth, which is ideal for us.\n",
    "\n",
    "A simple example ${\\bf x}={\\bf A}{\\bf \\theta}$, we know ${\\bf A}$, we know a noisy ${\\bf x}$, we need to find ${\\bf \\theta}$. In elastic net regression, we add regularization to find ${\\bf \\theta}$.\n",
    "\n",
    "Instead of *hand tuning* the regularization, we train an agent to self-learn what these regularization paramters should be.\n",
    "<img src=\"figures/enet_pipeline.png\" alt=\"Elastic net regression agent and environment\" width=\"500\"/>\n",
    "\n",
    "### Reinforcement learning\n",
    "An AI agent learns by itself, by trial and error, how to perform a task. Given the *state*, perform an *action* and receive a *reward*. There is a long history, and with the addition of deep neural networks, RL has made rapid progress recently: beating humans in Chess, Go, for example. In the example above, we have 5 deep neural networks, and we train them by running various trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('./elasticnet'))\n",
    "\n",
    "from enetenv import ENetEnv\n",
    "from enet_td3 import Agent\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    N=20 # rows = data points\n",
    "    M=20 # columns = parameters, note, N<M, so no unique solution\n",
    "    env = ENetEnv(M,N)\n",
    "    # actions: 2\n",
    "    agent = Agent(gamma=0.99, batch_size=64, n_actions=2, tau=0.005,\n",
    "                  max_mem_size=1000, input_dims=[N+N*M], lr_a=1e-3, lr_c=1e-3,\n",
    "                 update_actor_interval=2, warmup=100, noise=0.1)\n",
    "    # note: input dims: N eigenvalues+ N*M size of design matrix, \n",
    "    # lr_a: learning rate actor, lr_c:learning rate critic\n",
    "    scores=[]\n",
    "    n_games= 200\n",
    "\n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        loop=0\n",
    "        while (not done) and loop<2:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward,\n",
    "                                    observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "            loop+=1\n",
    "        score=score.cpu().data.item()/loop\n",
    "        scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        print('episode ', i, 'score %.2f' % score,\n",
    "                'average score %.2f' % avg_score)\n",
    "\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence maps\n",
    "Visualizing influence function in radio astronomical data (using 1 min data below):\n",
    "<img src=\"figures/influence_maps.png\" alt=\"Influence maps\" width=\"500\"/>\n",
    "\n",
    "Influence maps show what is hidden in the data: can we train a classifier to find out the hidden signals?\n",
    "\n",
    "### Smart calibration\n",
    "<img src=\"tmp/agent_pipeline.png\" alt=\"Calibration pipeline\" width=\"500\"/>\n",
    "We train an RL agent to automatically find out best calibration parameters: hyperparameters (regularization), sky model, resource allocation (number of CPU/GPU). We only use *a small amount of data* to make this tuning, and can automatically adjust the settings as the data are processed.\n",
    "\n",
    "We can also train RL agents for other tasks: RFI mitigation, image synthesis, anomaly detection etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information: [Code](https://github.com/SarodYatawatta/smart-calibration) [Paper](https://arxiv.org/abs/2102.03200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
